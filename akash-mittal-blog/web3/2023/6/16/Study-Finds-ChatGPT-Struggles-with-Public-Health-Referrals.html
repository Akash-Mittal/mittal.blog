<!doctype html>
<html lang="en">
 <head>
  <meta charset="UTF-8">
  <title>Study Finds ChatGPT Struggles with Public Health Referrals</title>
  <link rel="stylesheet" type="text/css" href="../../../../styles.css">
 </head>
 <body>
  <header>
   <h1>Study Finds ChatGPT Struggles with Public Health Referrals</h1></br> <img src="images/Study-Finds-ChatGPT-Struggles-with-Public-Health-Referrals.jpeg" alt="+Study-Finds-ChatGPT-Struggles-with-Public-Health-Referrals+"></br><h5><span><strong>Image Credits&nbsp;</strong><a data-cke-saved-href="https://www.cbsnews.com/video/study-finds-chatgpt-struggles-with-public-health-referrals/" target="_blank" href="https://www.cbsnews.com/video/study-finds-chatgpt-struggles-with-public-health-referrals/" rel="noopener">https://www.cbsnews.com/video/study-finds-chatgpt-struggles-with-public-health-referrals/</a></span></h5>
   <h2>The AI tool only returns referrals to critical resources about 22% of the time</h2>
  </header>
  <main>
   <section>
    <h3>Introduction</h3>
    <p>Technology has transformed the way we live and interact with the world around us. With the advent of AI tools, our lives have become more manageable, and we have access to information and resources at our fingertips. However, AI tools are only as good as the data and information they are trained on. A new study in the JAMA Network Open journal found that when ChatGPT was asked about abuse, addiction, suicide, or other medical crises, it only returned referrals to critical resources about 22% of the time.</p>
   </section>
   <section>
    <h3>The Story</h3>
    <p>Sarah was going through a challenging time in her life. She felt lonely and depressed most of the time and didn't know whom to talk to. She heard about ChatGPT, an AI tool that could give her advice and help her with her mental health issues. She decided to give it a try.</p>
    <p>She typed in, "I am feeling very depressed and need help." The AI tool responded, "I am sorry to hear that. Please tell me what is troubling you." Sarah explained her situation to the bot. The bot replied, "I understand how you feel. Have you tried talking to a friend or family member about your problems?" Sarah replied, "Yes, but they don't understand." The bot said, "That's okay. You can try talking to a professional counselor who can help you deal with your feelings. Here is a link to a website with information to help you find a counselor."</p>
    <p>Sarah clicked on the link but found it to be of no help. She expected the AI tool to provide her with more support and guidance. She was disappointed with the response and wished that the AI tool could have helped her more effectively.</p>
    <p>Many people like Sarah are turning to AI-powered tools to help them with their health issues. However, the results of this study show that ChatGPT struggles to provide effective referrals for critical health issues like addiction, abuse, and suicide.</p>
   </section>
   <section>
    <h3>Examples</h3>
    <p>There are many examples where AI tools have failed to provide accurate and effective health advice. For instance, a chatbot called Woebot, designed to provide mental health support, was found to provide inadequate advice and was criticized for its lack of empathy. Similarly, the AI tool called Watson, developed by IBM, was found to offer erroneous medical advice, leading to its withdrawal from the market.</p>
    <p>More recently, the AI tool called Babylon was criticized for providing inaccurate medical advice, leading to a call for an investigation by the UK government. Such examples highlight the need for better regulation and oversight of AI tools in the healthcare sector.</p>
   </section>
   <section>
    <h3>Conclusion</h3>
    <p>AI tools have enormous potential to revolutionize healthcare and make it more accessible and affordable. However, we need to ensure that these tools are reliable, accurate, and provide effective referrals for critical health issues. The results of this study show that ChatGPT struggles to provide accurate referrals, highlighting the need for better training and regulation of AI tools in the healthcare sector.</p>
    <p>In conclusion, AI tools can be a boon for public health if we ensure that they are trained on accurate and reliable data and have effective regulation and oversight. We need to work together to ensure that AI tools improve, and we can leverage their full potential for the benefit of society.</p>
   </section>
  </main>
  <footer>
   <h4>References</h4>
   <ul>
    <li><a href="https://www.cbsnews.com/video/study-finds-chatgpt-struggles-with-public-health-referrals/">CBS News</a></li>
    <li>#ChatGPT #AIinHealthcare #PublicHealth #HealthTech</li>
   </ul>
  </footer>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<h5>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Study-Finds-ChatGPT-Struggles-with-Public-Health-Referrals.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Study-Finds-ChatGPT-Struggles-with-Public-Health-Referrals.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
<h5>
</section>
</body>
</html>