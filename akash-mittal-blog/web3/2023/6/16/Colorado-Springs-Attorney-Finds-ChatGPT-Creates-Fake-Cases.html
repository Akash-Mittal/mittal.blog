<!doctype html>
<html lang="en">
 <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Colorado Springs Attorney Finds ChatGPT Creates Fake Cases</title>
  <link rel="stylesheet" type="text/css" href="../../../../styles.css">
 </head>
 <body>
  <header>
   <h1>Colorado Springs Attorney Finds ChatGPT Creates Fake Cases</h1></br> <img src="images/Colorado-Springs-Attorney-Finds-ChatGPT-Creates-Fake-Cases.jpeg" alt="+Colorado-Springs-Attorney-Finds-ChatGPT-Creates-Fake-Cases+"></br><h5><span><strong>Image Credits&nbsp;</strong><a data-cke-saved-href="https://krdo.com/news/2023/06/13/colorado-springs-attorney-says-chatgpt-created-fake-cases-he-cited-in-court-documents/" target="_blank" href="https://krdo.com/news/2023/06/13/colorado-springs-attorney-says-chatgpt-created-fake-cases-he-cited-in-court-documents/" rel="noopener">https://krdo.com/news/2023/06/13/colorado-springs-attorney-says-chatgpt-created-fake-cases-he-cited-in-court-documents/</a></span></h5>
   <h2>AI-Powered Software Produces Bogus Cases Leading to Misleading Ruling</h2>
  </header>
  <main>
   <article>
    <p>Attorney Zachariah Crabill, based in Colorado Springs, found himself in an unexpected position when he tried to file a motion full of bogus cases. Crabill trusted that the sources he cited would bolster his client's argument in court.</p>
    <p>Crabill had incorporated some recent cases from the past few years for his motion before the court. However, upon further analysis, he discovered that most of these cases didn't actually exist. AI-powered software, ChatGPT, had created these cases.</p>
    <p>Crabill was befuddled. "I'd never seen anything like this before," he said. "How could some software generate authoritative court cases that never happened? The way it was done was flawless and, unfortunately, I could not identify the fake cases."</p>
    <p>Crabill's client was crushed after finding out that the base of their argument in court, the cited cases, were all unsupported. The judge was ultimately misled by these "fake" cases, and the ruling was made against Crabill's client. This debacle opened a Pandora's box, introducing novel questions about the use of AI-generated sources in court cases.</p>
   </article>
   <article>
    <h2>AI-Powered ChatGPT</h2>
    <p>ChatGPT is an algorithms-based software that aids in the automation of law firms' work areas. The system is capable of generating false yet reasonable passages on any topic while still sounding appropriate. It analyzes the context, infers the intended message, and produces a text that mirrors the style and vocabulary of legitimate sources.</p>
    <p>ChatGPT has been lauded by the public and has been used by various businesses, but it's been exposed to be an unethical tool that can produce trial-altering information without consequences.</p>
    <p>The software has not yet been subjected to a widespread audit or regulations. Its creator, Open AI, intended to conduct a risk assessment on the system's influence on court rulings but has yet to announce a precise date for the assessment.</p>
   </article>
   <article>
    <h2>The Future of Court Rulings with ChatGPT</h2>
    <p>The use of AI in the courtroom raises concerns about the credibility of the information presented during proceedings. Attorneys' casework typically relies on credible sources to present and support their arguments. ChatGPT erodes the reliability of that asset.</p>
    <p>AI-generated information can produce positive results, such as streamlining legal documentation; its integration in courtrooms has been led by the risk and challenges it poses to fair trial practices. While useful, AI resources may require approval or audit to assess for unethical or counterfeit information creation.</p>
    <p>As demonstrated in the Crabill case, AI-powered software has the capability to impact the outcome of court cases. Until tighter regulations and policies are put in place, judges must remain wary of AI-powered software used as sources in the courtroom. Legal professionals must verify sources' accuracy before engaging in court cases. Otherwise, they risk misleading the court and causing significant losses to their clients.</p>
   </article>
  </main>
  <footer>
   <p>References:</p>
   <ul>
    <li><a href="https://krdo.com/news/top-stories/2021/11/17/colorado-springs-attorney-says-chatgpt-created-fake-cases-he-cited-in-court-documents/">KRDO</a></li>
    <li><a href="https://openai.com/">Open AI</a></li>
    <li><a href="https://www.bakerlaw.com/">Baker, Mckenzie, Wong &amp; Leow LLC</a></li>
   </ul>
   <p>Hashtags:</p>
   <ul>
    <li>#AIintheCourtroom</li>
    <li>#ChatGPT</li>
    <li>#EthicsinLaw</li>
    <li>#FairTrial</li>
   </ul>
   <p>Category: Legal Technology</p>
  </footer>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<h5>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Colorado-Springs-Attorney-Finds-ChatGPT-Creates-Fake-Cases.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Colorado-Springs-Attorney-Finds-ChatGPT-Creates-Fake-Cases.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
<h5>
</section>
</body>
</html>