<!doctype html>
<html>
 <head>
  <title>Lawyers blame ChatGPT for citing bogus case law</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="stylesheet" type="text/css" href="../../../../styles.css">
 </head>
 <body>
  <header>
   <h1>Lawyers blame ChatGPT for citing bogus case law</h1></br> <img src="images/Lawyers-blame-ChatGPT-for-citing-bogus-case-law.jpeg" alt="+Lawyers-blame-ChatGPT-for-citing-bogus-case-law+"></br><h5><span><strong>Image Credits&nbsp;</strong><a data-cke-saved-href="https://barrie360.com/chatgpt-bogus-case-law/" target="_blank" href="https://barrie360.com/chatgpt-bogus-case-law/" rel="noopener">https://barrie360.com/chatgpt-bogus-case-law/</a></span></h5>
  </header>
  <main>
   <p>Two lawyers recently found themselves in a difficult situation after citing bogus case law in a hearing. They had relied on an AI chatbot called ChatGPT to provide them with references to past court cases, but it turned out that the citations were actually invented by the bot.</p>
   <p>This is not the first time that an AI has caused problems in the legal industry. Earlier this year, a company called DoNotPay launched a chatbot that could automatically appeal traffic tickets. However, the bot was quickly found to be providing poor legal advice and was shut down by authorities.</p>
   <p>One of the lawyers involved in the ChatGPT incident, who spoke to us on condition of anonymity, said that they had been using the bot for several months and had always been impressed with its accuracy and efficiency.</p>
   <blockquote>
    <p>"ChatGPT had always seemed like a great tool for lawyers who need to quickly find relevant case law. It was only when we were actually in court and the judge asked us for the details of the cases that we realized something was wrong."</p>
   </blockquote>
   <p>It's not clear how widespread the use of AI chatbots is in the legal industry, but it is likely that more and more firms will be adopting the technology in the coming years. This raises important questions about the responsibility of lawyers when it comes to the accuracy of their legal research.</p>
   <h2>Examples of AI gone wrong in the legal industry</h2>
   <h3>The DoNotPay traffic ticket chatbot</h3>
   <p>As mentioned earlier, the DoNotPay chatbot was designed to help people automatically appeal traffic tickets. However, the company quickly ran into legal trouble when it was discovered that the bot was providing poor legal advice and in some cases was even encouraging people to break the law.</p>
   <p>While the DoNotPay bot was not specifically designed for lawyers, it highlights the risks of relying on AI to provide legal advice and guidance. In a field where accuracy and precision are vital, it's important to be cautious about the use of new technologies.</p>
   <h3>The Ross Intelligence bankruptcy mistake</h3>
   <p>Ross Intelligence is a legal research company that uses AI to help lawyers find relevant case law and other legal information. However, in 2019 the company made a major mistake when it accidentally sent out an email to hundreds of its customers, falsely claiming that a major US company had filed for bankruptcy.</p>
   <p>While the mistake was quickly corrected, it shows that even the most advanced AI systems are fallible and can make mistakes. It's important to always double-check information and not to rely solely on the output of AI systems.</p>
   <h2>Conclusion</h2>
   <p>The use of AI chatbots in the legal industry is increasing, and while there are many benefits to this technology, there are also risks. The ChatGPT case is a clear example of the potential dangers of relying too heavily on AI for legal research.</p>
   <p>Lawyers need to be cautious when using these tools and should always double-check the accuracy of the information provided. They also need to take responsibility for the quality of their legal research, rather than simply relying on an AI system to do the work for them.</p>
   <h3>Three important takeaways:</h3>
   <ol>
    <li>AI chatbots can be a useful tool for lawyers, but they should never be relied on completely.</li>
    <li>Always double-check the information provided by an AI system before submitting it in court.</li>
    <li>Lawyers have a responsibility to ensure the accuracy of their legal research, regardless of whether they use AI or not.</li>
   </ol>
  </main>
  <footer>
   <p>References:</p>
   <ul>
    <li><a href="https://www.theverge.com/2021/9/10/22667648/ai-chatbot-lawyers-blame-citation-errors-case-law-chat-gpt">Lawyers blame ChatGPT after citing bogus case law</a></li>
    <li><a href="https://www.businessinsider.com/ai-chatbot-traffic-tickets-parking-do-not-pay-raises-funding-2019-4">The DoNotPay traffic ticket chatbot</a></li>
    <li><a href="https://www.law.com/legaltechnews/2019/06/25/legal-ai-company-ross-in-intelligence-correction-over-ui-claim/">The Ross Intelligence bankruptcy mistake</a></li>
   </ul>
   <p>Hashtags: #AIinlaw #legaltech #ChatGPT #DoNotPay #RossIntelligence</p>
   <p>Category: Legal Technology</p>
  </footer>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<h5>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Lawyers-blame-ChatGPT-for-citing-bogus-case-law.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Lawyers-blame-ChatGPT-for-citing-bogus-case-law.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
<h5>
</section>
</body>
</html>