<!doctype html>
<html>
 <head>
  <title>NTIA Receives Over 1,450 Comments On AI Accountability</title>
  <meta charset="UTF-8">
  <meta name="keywords" content="NTIA, Artificial Intelligence, AI Accountability">
  <meta name="description" content="NTIA receives over 1,450 comments on AI accountability. Find out what this means for the future of AI and its impact.">
  <meta name="author" content="ArticleWriter">
  <link rel="stylesheet" type="text/css" href="../../../../styles.css">
 </head>
 <body>
  <header>
   <h1>NTIA Receives Over 1,450 Comments On AI Accountability</h1></br> <img src="images/NTIA-Receives-Over-1-450-Comments-On-AI-Accountability.jpeg" alt="+NTIA-Receives-Over-1-450-Comments-On-AI-Accountability+"></br><h5><span><strong>Image Credits&nbsp;</strong><a data-cke-saved-href="https://www.searchenginejournal.com/ntia-ai-accountability/489587/" target="_blank" href="https://www.searchenginejournal.com/ntia-ai-accountability/489587/" rel="noopener">https://www.searchenginejournal.com/ntia-ai-accountability/489587/</a></span></h5>
  </header>
  <main>
   <article>
    <section id="story">
     <p>Imagine a world where machines made all the decisions. A world where a single algorithm decides who gets hired for a job, who gets approved for a loan, and who gets access to life-saving medical treatments. This is the world that we are rapidly moving towards as Artificial Intelligence (AI) becomes more prevalent in our society.</p>
     <p>However, what happens when things go wrong? Who is accountable for the actions of these machines, and more importantly, who is responsible for the outcomes of their decisions? This is a question that the National Telecommunications and Information Administration (NTIA) sought to answer, when it opened a call for public comments on AI accountability.</p>
    </section>
    <section id="examples">
     <h2>Examples of AI Accountability Issues</h2>
     <p>The need for AI accountability has never been more evident than it is today. Numerous cases of AI systems making biased decisions have been reported, leading to discrimination and unfair treatment of certain groups. For example, Amazon's AI recruitment tool was found to be biased against women, while facial recognition technology has been shown to be less accurate for people of color.</p>
     <p>Another issue is that AI systems can often be opaque and difficult to understand. This makes it hard to pinpoint where things went wrong, and who is responsible for the outcome. In one case, an AI system used to predict which prisoners would reoffend was found to be racially biased. However, it was not clear how the system arrived at its decision, making it nearly impossible to fix the problem.</p>
    </section>
    <section id="conclusion">
     <h2>Conclusion</h2>
     <ol>
      <li>The sheer volume of comments received by the NTIA shows that there is a growing concern among the public about AI accountability. Policymakers and industry leaders alike need to take this seriously, and work together to create a framework for accountability that is transparent and effective.</li>
      <li>We need to recognize that AI is not perfect, and it will make mistakes. However, it is important to ensure that these mistakes can be corrected, and that those responsible are held accountable. This will require collaboration between developers, policymakers, and ethicists to create an AI system that is ethical and transparent.</li>
      <li>Ultimately, the future of AI depends on our ability to ensure that it is used safely, fairly, and ethically. The NTIA's call for comments on AI accountability is an important step towards achieving this goal, and we must continue to push for more accountability and transparency in AI systems.</li>
     </ol>
    </section>
   </article>
  </main>
  <footer>
   <ul>
    <li><a href="#references">References</a></li>
    <li>Social Media:</li>
    <li>#NTIA #ArtificialIntelligence #AIAccountability</li>
    <li>Article Category: Science &amp; Technology</li>
   </ul>
  </footer>
  <div id="references">
   <h2>References</h2>
   <ul>
    <li><a href="https://www.ntia.gov/" target="_blank">NTIA</a></li>
    <li><a href="https://www.theverge.com/2018/9/27/17909624/amazon-ai-recruitment-tool-gender-bias" target="_blank">Amazon's AI recruitment tool was biased against women</a></li>
    <li><a href="https://www.nytimes.com/2020/01/20/technology/facial-recognition-race.html" target="_blank">Facial recognition technology less accurate for people of color</a></li>
    <li><a href="https://www.theguardian.com/technology/2020/jan/24/algorithmic-injustices-risks-of-ai" target="_blank">An AI system used to predict which prisoners would reoffend was found to be racially biased</a></li>
   </ul>
  </div>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<h5>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/NTIA-Receives-Over-1-450-Comments-On-AI-Accountability.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/NTIA-Receives-Over-1-450-Comments-On-AI-Accountability.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
<h5>
</section>
</body>
</html>