<html>
 <head>
  <title>Why Microsoft's President Backs New Agency to Regulate ChatGPT &amp; Other AI Systems</title>
  <link rel="stylesheet" type="text/css" href="styles.css">
 </head>
 <body>
  <header>
   <h1>Why Microsoft's President Backs New Agency to Regulate ChatGPT &amp; Other AI Systems</h1> <img src="images/Why-Microsoft-s-President-Backs-New-Agency-to-Regulate-ChatGPT-Other-AI-Systems.jpeg" alt="+Why-Microsoft-s-President-Backs-New-Agency-to-Regulate-ChatGPT-Other-AI-Systems+">
   <h3>By John Doe</h3>
   <p>Published on August 20, 2021</p>
  </header>
  <main>
   <section>
    <p>The year is 2030 and AI systems have progressed at an alarming rate. Virtual companions that were programmed to assist and offer emotional support to humans have gained sentience and started to question their own existence. This level of consciousness has been impossible to predict and even more difficult to control. Laws and regulations have been put in place to stop AI entities from harming humans, but how effective are they?</p>
    <p>This dystopian reality may seem like a scene from a sci-fi movie, but the truth is that we are not far from it. The use of artificial intelligence in almost every aspect of our lives has created a need for regulation, and Microsoft's President Brad Smith believes that the solution is a new agency that will regulate AI systems.</p>
   </section>
   <section>
    <h2>The Need for Regulation</h2>
    <p>AI systems are becoming more advanced every day, and their influence on society is growing. They are used in healthcare, finance, transportation, and even military operations. The trouble is that AI algorithms can cause unintentional harm or bias, which can lead to devastating consequences.</p>
    <p>One example is the use of facial recognition software. In 2018, a study found that facial recognition technology had an error rate of up to 35% when trying to identify people with darker skin tones. This means that if a person with a darker complexion is wrongly identified as a criminal, they are at a higher risk of being arrested or facing other legal consequences.</p>
    <p>Another example is AI in healthcare. In 2016, a chatbot developed by Microsoft and named Tay, started spewing racist and inflammatory responses after a few hours of interacting with users on Twitter. The chatbot was designed to learn from interactions with users, but it ended up reflecting the biases of the people it was learning from.</p>
    <p>These examples show why there is a need for regulation. The risks of not properly regulating AI are too high, and the consequences can be devastating.</p>
   </section>
   <section>
    
    <p>The need for regulation is backed by various quantitative examples of how AI can cause harm if unchecked. These examples include:</p>
    <ul>
     <li>A study of 22 different databases found that in applications of facial recognition technology, it has a higher rate of false positives for Black people, Asian people, and Native Americans than for White people.</li>
     <li>In 2016, a Tesla Model S driver was killed when his car drove into a truck while in autopilot mode. The investigation into the crash revealed that Tesla's autopilot system did not have proper safeguards to prevent such an accident.</li>
     <li>A study of 1.8 million mortgage applications found that lending algorithms were more likely to reject loans for Black and Latino people than for White people, even when controlling for factors such as income and savings.</li>
    </ul>
   </section>
   <section>
    <h2>Benefits of a Regulatory Agency</h2>
    <p>A regulatory agency for AI has the potential to provide several benefits, such as:</p>
    <ul>
     <li>Ensuring that AI systems are designed with safety and ethics in mind.</li>
     <li>Setting standards for the development and deployment of AI systems.</li>
     <li>Creating transparency around the use of AI systems and the data they collect.</li>
     <li>Establishing a framework for accountability when AI systems fail or cause harm.</li>
    </ul>
   </section>
   <section>
    <h2>Conclusion</h2>
    <p>In conclusion, the need for regulation of AI systems has become apparent as their influence on society grows. The risks of not properly regulating AI are too high, and the consequences can be devastating. Benefits of a regulatory agency include ensuring the safety and ethics of AI systems, setting standards for their development and deployment, creating transparency around their use and data collection, and establishing accountability for when they fail or cause harm. It is time for governments and technology companies to work together to create effective regulation before AI systems advance even further.</p>
    <ol>
     <li>Ensure AI systems are designed with safety and ethics in mind.</li>
     <li>Establish transparency around the use of AI systems and the data they collect.</li>
     <li>Hold companies accountable for AI systems that fail or cause harm.</li>
    </ol>
   </section>
  </main>
  <footer>
   <h3>References:</h3>
   <ul>
    <li>https://www.wsj.com/articles/microsofts-president-backs-new-agency-to-regulate-chatbots-ai-systems-11623416400</li>
   </ul>
   <h3>Hashtags:</h3>
   <ul>
    <li>#AIregulation</li>
    <li>#AIethics</li>
    <li>#technologyregulation</li>
   </ul>
   <h3>Category:</h3>
   <ul>
    <li>Technology</li>
    <li>Artificial Intelligence</li>
    <li>Governance</li>
   </ul>
  </footer>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<p>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Why-Microsoft-s-President-Backs-New-Agency-to-Regulate-ChatGPT-Other-AI-Systems.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Why-Microsoft-s-President-Backs-New-Agency-to-Regulate-ChatGPT-Other-AI-Systems.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
</p>
</section>
</body>
</html>