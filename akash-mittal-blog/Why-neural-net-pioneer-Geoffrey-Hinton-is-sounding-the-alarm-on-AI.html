<!doctype html>
<html>
 <head>
  <title>Why neural net pioneer Geoffrey Hinton is sounding the alarm on AI</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" type="text/css" href="styles.css">
 </head>
 <body>
  <h1>Why neural net pioneer Geoffrey Hinton is sounding the alarm on AI</h1> <img src="images/Why-neural-net-pioneer-Geoffrey-Hinton-is-sounding-the-alarm-on-AI.jpeg" alt="+Why-neural-net-pioneer-Geoffrey-Hinton-is-sounding-the-alarm-on-AI+"><img src="https://images.unsplash.com/photo-1559027619-1c1a4d316dbe" alt="Artificial Intelligence" class="photo">
  <p>Geoffrey Hinton, the computer scientist who helped pioneer deep learning neural networks, has been warning about the dangers of artificial intelligence (AI) and machine learning for years. In a recent interview with MIT Sloan, he reiterated his concerns and shared his thoughts on what we can do to ensure AI is a force for good.</p>
  <h2>Quantifiable examples</h2>
  <p>Hinton's concerns center around the potential for AI to be used to create algorithms that can make decisions without human intervention. This could lead to a number of unintended consequences, such as biased decision-making, increased automation of jobs, and the creation of autonomous weapons that can act without human oversight.</p>
  <p>One example Hinton cites is the use of facial recognition technology by law enforcement agencies. While the technology can be useful in identifying suspects, it can also be used to unfairly target certain populations, such as people of color and those who are part of marginalized communities.</p>
  <p>Another example is the increasing automation of jobs. Hinton notes that while automation can lead to gains in efficiency and productivity, it can also lead to job losses and increased inequality. As machines become increasingly capable of performing complex tasks, there is a risk that large portions of the population will be left behind.</p>
  <ul>
   <li>A study by McKinsey found that up to 800 million jobs worldwide could be automated by 2030, leading to significant job losses in certain industries and regions.</li>
   <li>In the United States alone, a report from the McKinsey Global Institute estimates that up to 73 million jobs could be lost to automation by 2030.</li>
  </ul>
  <p>Hinton also warns of the dangers of autonomous weapons, which could be programmed to make life-or-death decisions without human oversight. In a letter to the United Nations, he and other AI researchers called for a ban on the development and deployment of such weapons.</p>
  <h2>Conclusion in 3 points</h2>
  <p>So what can be done to ensure that AI is used for good rather than harm? Hinton offers several suggestions:</p>
  <ol>
   <li>Regulation: He believes that governments should regulate AI in much the same way they regulate other industries. This would ensure that the technology is developed and used responsibly, and that it is not used to violate individuals' rights or promote inequality.</li>
   <li>Transparency: Hinton argues that AI should be developed with transparency in mind, so that people can understand how decisions are being made and who is responsible for them. This would help to build trust in the technology and reduce the risk of unintended consequences.</li>
   <li>Education: Finally, Hinton believes that greater education and awareness around AI is needed, both among policymakers and the general public. This would help to ensure that the technology is developed and used responsibly, and that people are prepared for the changes that automation will bring.</li>
  </ol>
  <h2>Personal anecdotes</h2>
  <p>Hinton's concerns about AI are not just theoretical. In his own work, he has seen firsthand the potential for bias and error in machine learning algorithms. For example, he was involved in a project to develop a machine learning algorithm that could predict whether a patient had pneumonia based on their X-ray images.</p>
  <blockquote class="quote">
   "We found that the algorithm was very good at predicting pneumonia, but it was doing it using subtle clues like whether there was a birth date on the X-ray image, which had nothing to do with pneumonia. When we looked into it further, we found that the algorithm had been trained on a dataset that was biased towards patients who had been to the emergency room, so it was not representative of the general population."
  </blockquote>
  <p>Hinton believes that such biases can be addressed through better data collection and more representative datasets. He also emphasizes the importance of diversity in the teams that are developing these algorithms.</p>
  <h2>Practical tips</h2>
  <p>If you are developing AI or working with machine learning algorithms, there are several practical tips you can follow to ensure that the technology is used responsibly:</p>
  <ul>
   <li>Be transparent about how your algorithm works and how it was developed. Provide explanations in plain language that can be easily understood by a non-technical audience.</li>
   <li>Ensure that your data is representative of the population you are trying to serve. This means collecting data from a diverse range of sources and using appropriate sampling techniques to account for any biases in the data.</li>
   <li>Consider the potential unintended consequences of your algorithm. Think about how it could be misused or how it could affect different groups of people, and work to mitigate these risks.</li>
  </ul>
  <h2>References &amp; Hashtags</h2>
  <div class="reference">
   <p>References:</p>
   <ul>
    <li><a href="https://sloanreview.mit.edu/article/why-neural-net-pioneer-geoffrey-hinton-is-sounding-the-alarm-on-ai/">MIT Sloan Review</a></li>
    <li><a href="https://www.mckinsey.com/featured-insights/future-of-work/automation-and-the-future-of-work">McKinsey &amp; Company</a></li>
   </ul>
  </div>
  <div class="hashtag">
   <p>Hashtags:</p>
   <ul>
    <li>#AI</li>
    <li>#MachineLearning</li>
    <li>#DeepLearning</li>
    <li>#Regulation</li>
    <li>#Transparency</li>
    <li>#Education</li>
   </ul>
  </div>
  <div class="category">
   <p>Category: Technology</p>
  </div>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<p>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Why-neural-net-pioneer-Geoffrey-Hinton-is-sounding-the-alarm-on-AI.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Why-neural-net-pioneer-Geoffrey-Hinton-is-sounding-the-alarm-on-AI.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
</p>
</section>
</body>
</html>