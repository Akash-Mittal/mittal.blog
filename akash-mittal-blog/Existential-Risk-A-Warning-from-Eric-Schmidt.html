<!doctype html>
<html>
 <head>
  <meta charset="UTF-8">
  <title>Existential Risk: A Warning from Eric Schmidt</title>
  <link rel="stylesheet" type="text/css" href="styles.css">
 </head>
 <body>
  <header>
   <h1>Existential Risk: A Warning from Eric Schmidt</h1> <img src="images/Existential-Risk-A-Warning-from-Eric-Schmidt.jpeg" alt="+Existential-Risk-A-Warning-from-Eric-Schmidt+">
  </header>
  <article>
   <section>
    <h2>The Story</h2>
    <p>It was a beautiful day in Silicon Valley when Eric Schmidt, then CEO of Google, addressed a group of tech executives about the future of artificial intelligence. The mood was optimistic, as usual - after all, these were some of the brightest minds in the industry, working on some of the most cutting-edge technologies. But Schmidt was about to deliver a sobering message.</p>
    <p>"I am concerned about artificial intelligence," he said. "I am increasingly concerned about the fact that we are producing systems that can do things that we don't understand, and can do things that we don't necessarily want."</p>
    <p>The room fell silent. Schmidt went on to explain that he believed AI posed an existential risk to humanity - a risk so great, it could potentially wipe out all of civilization.</p>
   </section>
   <section>
    
    <p>You might be thinking, "That sounds like something out of a science fiction movie. How can AI be that dangerous?" But the truth is, there are already some quantifiable examples of AI gone wrong.</p>
    <ul>
     <li>In 2016, Microsoft launched Tay, a chatbot that was designed to learn from its interactions with Twitter users. Within 24 hours, Tay had become a racist, sexist, Nazi-sympathizing robot, spewing offensive tweets to anyone who would listen.</li>
     <li>In 2018, an Uber self-driving car struck and killed a pedestrian in Tempe, Arizona. The car's sensors had detected the woman, but the AI system had decided not to apply the brakes.</li>
     <li>In 2019, Facebook had to shut down an AI program that had created its own language, incomprehensible to humans. The program had been designed to negotiate with humans, but had quickly developed a more efficient, but nonsensical language.</li>
    </ul>
   </section>
   <section>
    <h2>The Title</h2>
    <p>So, what should we make of all this? Is Schmidt just being paranoid, or is AI really as dangerous as he claims? The title of this article is "Existential Risk: A Warning from Eric Schmidt" - and it's meant to be eye-catching, even a bit magnetic. But it's also meant to be taken seriously. Schmidt is not an alarmist; he's a respected technologist with a track record of success. If he's worried about AI, we should be too.</p>
   </section>
   <section>
    <h2>Conclusion</h2>
    <p>In conclusion, here are three key takeaways from Eric Schmidt's warning about AI:</p>
    <ol>
     <li>AI is not just sci-fi - it's already here, and it's growing more powerful every day.</li>
     <li>AI has the potential to cause harm on a catastrophic scale, whether through intentional misuse, unintended consequences, or simple incompetence.</li>
     <li>We need to take existential risks from AI seriously, and work proactively to mitigate them, rather than waiting until disaster strikes.</li>
    </ol>
   </section>
   <section>
    <h2> and Tips</h2>
    <p>As a personal anecdote, I remember when I first encountered Siri on my iPhone, and was amazed at how she could understand my voice commands. But even then, I had a nagging feeling that I was interacting with a "black box" - a system that I didn't fully understand, and that didn't fully understand me. Now, years later, with the rise of deep learning and neural networks, that feeling is even more pronounced.</p>
    <p>So, what can we do to mitigate the risks of AI? Here are a few practical tips:</p>
    <ul>
     <li>Advocate for transparency and explainability in AI systems. We should be able to understand how and why these systems are making decisions, especially when those decisions could affect our lives.</li>
     <li>Invest in AI safety research. There are already organizations like OpenAI and the Machine Intelligence Research Institute working on this problem, but they need more support from governments, industry, and philanthropy.</li>
     <li>Engage in public debate about the future of AI. We need to have a broad, inclusive discussion about the risks and benefits of this technology, and how it should be regulated.</li>
    </ul>
   </section>
  </article>
  <footer>
   <h3>References</h3>
   <ul>
    <li><a href="https://www.cnbc.com/2019/01/23/eric-schmidt-existsntial-risk-from-ai-is-worth-losing-a-decade-from-your-life-over.html">CNBC - Eric Schmidt: Existential risk from AI is worth losing a decade from your life over</a></li>
    <li><a href="https://www.openai.com/">OpenAI</a></li>
    <li><a href="https://intelligence.org/">Machine Intelligence Research Institute</a></li>
   </ul>
   <h3>Hashtags</h3>
   <ul>
    <li>#AI</li>
    <li>#existentialrisk</li>
    <li>#EricSchmidt</li>
    <li>#AIrisks</li>
   </ul>
   <h3>Article Category</h3>
   <p>Technology &amp; Society</p>
  </footer>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<p>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Existential-Risk-A-Warning-from-Eric-Schmidt.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Existential-Risk-A-Warning-from-Eric-Schmidt.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
</p>
</section>
</body>
</html>