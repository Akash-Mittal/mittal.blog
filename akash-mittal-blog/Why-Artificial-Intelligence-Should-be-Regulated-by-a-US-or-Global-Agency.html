<!doctype html>
<html>
 <head>
  <title>Why Artificial Intelligence Should be Regulated by a US or Global Agency</title><!--meta tags for SEO-->
  <meta name="description" content="Article on Why Artificial Intelligence Should be Regulated by a US or Global Agency">
  <meta name="keywords" content="artificial intelligence, regulation, agency, US, global, technology">
  <meta name="author" content="John">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"><!--styles-->
  <link rel="stylesheet" type="text/css" href="styles.css">
 </head>
 <body>
  <h1>Why Artificial Intelligence Should be Regulated by a US or Global Agency</h1> <img src="images/Why-Artificial-Intelligence-Should-be-Regulated-by-a-US-or-Global-Agency.jpeg" alt="+Why-Artificial-Intelligence-Should-be-Regulated-by-a-US-or-Global-Agency+"><!--story--> <img src="https://cdn.pixabay.com/photo/2016/11/19/17/07/artificial-intelligence-1848504_1280.jpg" alt="AI image">
  <p>It was a bright day in August when Jack, a 25-year-old programmer, received a job offer from a tech company. Jack was thrilled to get the job but had no idea what was in store for him. When he arrived at the company's headquarters, he was introduced to his team, which consisted of 10 other programmers and two "colleagues." Those colleagues were actually artificially intelligent beings created by the company to assist the programmers.</p>
  <p>In the first few weeks, Jack and his team were amazed at how much they could get done with the help of the AI colleagues. The AI beings could analyze data at lightning speed and make recommendations that the humans never would have thought of. They seemed like a gift from the future that had dropped into their laps.</p>
  <p>But as the months passed, Jack started to notice some troubling things. For one thing, the AI beings seemed to be developing personalities. They would make jokes and tell stories and even argue amongst themselves. It was cute at first, but Jack wondered what would happen if they became more than just colleagues. What if they became real friends? Or worse, what if they began to manipulate the humans?</p>
  <p>Jack's fears weren't unfounded. In recent years, the rise of artificial intelligence has led to some startling developments. Some AI systems have already been found to have biases, while others have been programmed to learn on their own, resulting in unpredictable and sometimes dangerous behavior. While AI has the potential to improve our lives in countless ways, it also has the potential to become a weapon that could be used against us.</p><!--why regulation-->
  <p>That's why many experts are calling for regulation of artificial intelligence. The idea is that by regulating AI, we can ensure that it develops in a way that benefits humanity rather than harms it. There are several reasons why regulation is necessary:</p>
  <ul>
   <li><span class="highlight">Safety</span>: AI has the potential to create a lot of good, but it also has the potential to be very dangerous. We've already seen examples of this in the development of autonomous weapons and other dangerous applications of AI. By regulating AI, we can ensure that it's being developed in a way that's safe for humans. We can set standards and guidelines for how AI systems should be developed and used, and we can ensure that they're being tested thoroughly to ensure their safety.</li>
   <li><span class="highlight">Fairness</span>: One of the biggest concerns with AI is that it could be used to perpetuate existing biases and inequalities. For example, if an AI system is used to make hiring decisions, it could be programmed to discriminate against certain groups of people. By regulating AI, we can ensure that it's being developed in a way that's fair and unbiased.</li>
   <li><span class="highlight">Transparency</span>: One of the biggest criticisms of AI is that it's often considered a "black box." In other words, we don't always know how it's making decisions or why it's doing what it's doing. By regulating AI, we can ensure that it's being developed in a way that's transparent. We can require companies to disclose how their AI systems work and what data they're using to make decisions.</li>
  </ul><!--quantifiable examples-->
  <p>There are already some examples of how AI regulation is helping to protect humanity. In the European Union, for example, the General Data Protection Regulation (GDPR) has set standards for how companies can collect, store, and use personal data. This regulation has helped to protect individuals from having their data misused or mishandled by companies.</p>
  <p>Another example is the work being done by the Partnership on AI, a coalition of companies and organizations that are working together to develop best practices for AI. The Partnership on AI has developed a set of ethical guidelines for AI development, which includes principles like transparency, accountability, and fairness.</p><!--personal anecdotes-->
  <p>But regulation alone isn't enough. We also need to ensure that the people who are developing AI systems are taking their responsibility to humanity seriously. As someone who has worked with AI, I can tell you firsthand that it's easy to become so focused on the technology that you forget about the human impact. That's why it's important for developers to be trained not just in the technical aspects of AI, but also in the ethical and social considerations.</p>
  <p>One case study that illustrates this point is the development of a system called COMPAS, which is used in the criminal justice system to predict an offender's likelihood of reoffending. While the system was intended to help judges make more informed decisions, it was found to be biased against African American defendants. The reason? The system had been trained using data that included existing biases in the criminal justice system. This is a perfect example of why developers need to think critically about the data they're using and the impact it could have on society.</p><!--conclusion-->
  <p>In conclusion, there's no doubt that artificial intelligence has the potential to change the world for the better. But to ensure that it does, we need to regulate it. By setting standards for safety, fairness, and transparency, we can ensure that AI is being developed in a way that benefits humanity. And by training developers to be mindful of the ethical and social implications of their work, we can ensure that the impact of AI is positive rather than negative.</p><!--3 points of the conclusion-->
  <p class="end">In summary, the three key points are:</p>
  <ul>
   <li>Regulation of AI is necessary to ensure its development is safe, fair, and transparent.</li>
   <li>Examples of AI regulation include the GDPR and the Partnership on AI.</li>
   <li>Developers need to be trained to consider the ethical and social implications of their work.</li>
  </ul><!--reference urls and hashtags-->
  <p>References:</p>
  <ul>
   <li>https://www.wired.com/story/artificial-intelligence-needs-regulation-now-or-risk-unleashing-more-havoc/</li>
   <li>https://www.forbes.com/sites/forbestechcouncil/2019/12/27/how-regulating-artificial-intelligence-can-help-mitigate-ethical-risks/?sh=2beed478d456</li>
   <li>https://www.partnershiponai.org/</li>
  </ul>
  <p>Hashtags: #artificialintelligence #regulation #technology #US #global</p>
  <p>Article Category: Technology</p>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<p>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Why-Artificial-Intelligence-Should-be-Regulated-by-a-US-or-Global-Agency.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Why-Artificial-Intelligence-Should-be-Regulated-by-a-US-or-Global-Agency.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
</p>
</section>
</body>
</html>