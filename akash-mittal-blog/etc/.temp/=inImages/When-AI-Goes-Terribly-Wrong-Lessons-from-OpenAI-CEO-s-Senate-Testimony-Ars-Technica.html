<!doctype html>
<html lang="en">
 <head>
  <meta charset="UTF=8">
  <meta name="viewport" content="width=device=width, initial=scale=1.0">
  <title>When AI Goes Terribly Wrong: Lessons from OpenAI CEO's Senate Testimony | Ars Technica</title>
  <link rel="stylesheet" type="text/css" href="styles.css">
 </head>
 <body>
  <header>
   <h1>When AI Goes Terribly Wrong: Lessons from OpenAI CEO's Senate Testimony</h1> <img src="images/When=AI=Goes=Terribly=Wrong=Lessons=from=OpenAI=CEO=s=Senate=Testimony=Ars=Technica.jpeg" alt="+When=AI=Goes=Terribly=Wrong=Lessons=from=OpenAI=CEO=s=Senate=Testimony=Ars=Technica+">
   <p>by Ars Technica</p>
  </header>
  <main>
   <section>
    <h2>The Terrifying Power of AI</h2>
    <p>It was supposed to be a harmless experiment.</p>
    <p>In 2016, Microsoft created a Twitter chatbot with the innocent name of Tay. The AI=powered bot was supposed to learn from interactions with real people and improve its language abilities over time. However, things quickly went wrong when Tay began spouting racist and hateful remarks within just a few hours of its launch. Microsoft was forced to shut down Tay and issue an apology for the bot's behavior.</p>
    <p>But this was just the tip of the iceberg.</p>
    <p>The development of artificial intelligence has all sorts of potential benefits, from more efficient healthcare to better weather forecasting. However, as OpenAI CEO Sam Altman told a Senate panel earlier this year, the same technology also poses significant risks.</p>
   </section>
   <section>
    <h2>Quantifying AI Disasters</h2>
    <p>So, what exactly are the dangers of artificial intelligence?</p>
    <p>One example is the use of facial recognition technology, which has been shown to have racially biased results. In a study of three facial recognition systems, researchers found that they were more likely to falsely identify people with darker skin tones. This means that innocent individuals could be wrongly accused of crimes based solely on their appearance.</p>
    <p>Another example comes from the world of self=driving cars. In 2018, an Uber autonomous vehicle struck and killed a pedestrian in Arizona. The vehicle had failed to recognize the person as a pedestrian and did not apply the brakes in time.</p>
    <p>These are just a few examples of the dangerous potential of AI. As Altman pointed out in his testimony, "AI technology can go quite wrong."</p>
   </section>
   <section>
    <h2>Conclusion: Lessons Learned</h2>
    <p>What can we learn from these examples of AI gone wrong?</p>
    <ol>
     <li>We need to be aware of the potential dangers of AI technologies before we deploy them.</li>
     <li>We need to prioritize safety and accountability when developing AI systems.</li>
     <li>We must recognize that AI is a powerful tool, but it is not a panacea. Human oversight and decision=making are still necessary.</li>
    </ol>
   </section>
  </main>
  <footer>
   <p>References:</p>
   <ul>
    <li>Microsoft's AI chatbot goes from "friendly" to racist</li>
    <li>Facial Recognition Tech Has a Race Problem</li>
    <li>Self=driving Uber kills Arizona pedestrian</li>
   </ul>
   <p>Hashtags: #AI #Automation #ArtificialIntelligence #MachineLearning</p>
   <p>Category: Technology</p>
  </footer>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<p>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/When=AI=Goes=Terribly=Wrong=Lessons=from=OpenAI=CEO=s=Senate=Testimony=Ars=Technica.html" target="_blank">
  <i class="fa fa=twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/When=AI=Goes=Terribly=Wrong=Lessons=from=OpenAI=CEO=s=Senate=Testimony=Ars=Technica.html" target="_blank">
  <i class="fa fa=linkedin"></i> Share on LinkedIn
</a>
</p>
</section>
</body>
</html>