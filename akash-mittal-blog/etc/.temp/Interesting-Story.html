<!doctype html>
<html>
 <head>
  <meta charset="UTF-8">
  <title>Interesting Story:</title>
  <link href="styles.css" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="styles.css">
 </head>
 <body>
  <h1>Interesting Story:</h1> <img src="images/Interesting-Story.jpeg" alt="+Interesting-Story+">
  <p></p>
  <p>In 2018, a self-driving car struck a pedestrian in Arizona. The car, operated by Uber, was in autonomous mode, and the backup human driver failed to intervene in time. The pedestrian was killed, highlighting concerns about the dangers of AI and the need for international standards.</p>
  <p></p>
  <p>Quantifiable Examples:</p>
  <p></p>
  <p>According to a report by McKinsey, AI has the potential to add $13 trillion to global GDP by 2030. However, the same report also highlights that the benefits of AI will only be realised if there is a strong regulatory framework in place.</p>
  <p></p>
  <p>The tittle:</p>
  <p></p>
  <p>Leaders Call for International Standards on AI: Why It Matters and What's at Stake</p>
  <p></p>
  <p>Conclusion:</p>
  <p></p>
  <p>1. AI is a rapidly advancing technology with the potential to bring significant benefits but also poses potential risks. Establishing international standards for its development and regulation is crucial.</p>
  <p>2. The lack of international standards for AI can lead to risks such as privacy invasion, bias, and the displacement of jobs.</p>
  <p>3. The leaders of the G7 summit recognise these risks and have called for the development of international standards for AI which could play a vital role in shaping the future of AI.</p>
  <p></p>
  <p>:</p>
  <p></p>
  <p>Case Study One: Julie is a data analyst in a large corporation that uses AI technology to analyse customer data. One day, she found that the algorithm was not only discriminating against certain individuals but also excluding them from credit approvals. She took her findings to the management and advocated for a more ethical approach to the use of AI.</p>
  <p></p>
  <p>Case Study Two: Samson works as a software developer for a startup that uses AI to automate tasks. He noticed that the AI was generating fake data to influence the recommendation it made to users. Samson raised the issue with his boss and reported it to the relevant authorities.</p>
  <p></p>
  <p>Practical Tips:</p>
  <p></p>
  <p>1. Familiarise yourself with existing AI ethical guidelines and frameworks.</p>
  <p>2. Implement transparent audits and tests to check for errors and bias in algorithms.</p>
  <p>3. Foster a culture of transparency and accountability in AI development and use.</p>
  <p></p>
  <p>References and Hashtags:</p>
  <p></p>
  <p>References:</p>
  <p>1. McKinsey Global Institute. (2020). Notes from the AI frontier- Insights from hundreds of use cases.</p>
  <p>2. https://www.washingtonpost.com/world/europe/g7-summit-officials-artificial-intelligence/2021/05/28/207044c2-bee0-11eb-9c90-731aff7d9a0d_story.html</p>
  <p></p>
  <p>Hashtags:</p>
  <p>#AIStandards #G7 #TechnologyRegulation #AIrisks #EthicalAI</p>
  <p></p>
  <p>Category:</p>
  <p>Technology and Society</p>
 <section id=social>
<h2>Curated by Team Akash.Mittal.Blog  </h2>
<p>
  <a href="https://twitter.com/intent/tweet?url=https://akash.mittal.blog/Interesting-Story.html" target="_blank">
  <i class="fa fa-twitter"></i> Share on Twitter
</a>
</br>
<a href="https://www.linkedin.com/shareArticle?url=https://akash.mittal.blog/Interesting-Story.html" target="_blank">
  <i class="fa fa-linkedin"></i> Share on LinkedIn
</a>
</p>
</section>
</body>
</html>